{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Path\n",
    "p_dssat = Path('./data/DSSAT')\n",
    "p_s1 = Path('./data/Sentinel-1')\n",
    "\n",
    "# finding the time that both parameters are available (LAI is daily but AMP is not)\n",
    "harvestdate=datetime.date(2017, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inputs\n",
    "input_list = ['LAI', 'SWTD', 'SWTD6', 'CWAD']\n",
    "df_list = []\n",
    "for key in input_list:\n",
    "    df = pd.read_pickle(p_dssat/\"brabant_{}.pkl\".format(key))\n",
    "    df.index = df.index.date\n",
    "    df_list.append(df)\n",
    "\n",
    "Brabant_LAI, Brabant_SWTD, Brabant_SWTD6, Brabant_CWAD = df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load outputs\n",
    "output_list = ['CR']\n",
    "df_list = []\n",
    "for key in output_list:\n",
    "    df = pd.read_pickle(p_s1/\"Amp_{}_New.pkl\".format(key))\n",
    "    df_list.append(df)\n",
    "Amp_CR_New = df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the temporal index (common dates)\n",
    "idx_time = Brabant_LAI.index.intersection(Amp_CR_New.index)\n",
    "idx_time = idx_time[idx_time<harvestdate]\n",
    "\n",
    "# Allign the spactial index (common field IDs)\n",
    "idx_space =  Brabant_LAI.columns.intersection(Amp_CR_New.columns)\n",
    "\n",
    "print(idx_time)\n",
    "print(idx_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an Xarray Dataset with coords\n",
    "ds = xr.Dataset(coords={\"space\": idx_space, \"time\": idx_time})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign input and outputs as data variables\n",
    "df_list = [Brabant_LAI, Brabant_SWTD, Brabant_SWTD6, Brabant_CWAD, Amp_CR_New]\n",
    "for k, v in zip(input_list + output_list, df_list):\n",
    "    v_sel = v.loc[idx_time, idx_space]\n",
    "    ds = ds.assign({k: ((\"time\", \"space\"), v_sel.values)})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing\n",
    "testing_split = 200 # reserve last n in space for testing\n",
    "idx_testing = ds.space[:200] # coordinates for testing data\n",
    "\n",
    "# Training dataset\n",
    "ds_training = ds.drop_sel(space=idx_testing)\n",
    "\n",
    "# Testing data\n",
    "ds_testing = ds.sel(space=idx_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Input and Output\n",
    "# Question: discontinuity caused be stacking?\n",
    "X = ds_training[input_list].stack(data=(\"space\", \"time\")).to_array().transpose(\"data\",\"variable\").values\n",
    "Y = ds_training[output_list].stack(data=(\"space\", \"time\")).to_array().transpose(\"data\", \"variable\").values.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSeachCV with DASK-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup grid search\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "regSVR = make_pipeline(MinMaxScaler(),SVR())\n",
    "kernel = [\"poly\",\"rbf\",\"sigmoid\"]\n",
    "C = [100,10,1,0.1]\n",
    "gamma = [\"scale\"]\n",
    "grid = dict(svr__kernel=kernel,svr__C=C,svr__gamma=gamma)\n",
    "cv = RepeatedKFold(n_splits=4,n_repeats=2,random_state=1)\n",
    "grid_search = GridSearchCV(estimator=regSVR, param_grid=grid, n_jobs=-1, cv=cv, scoring=[\"r2\",\"neg_mean_squared_error\"], refit=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal model fitting\n",
    "grid_result = grid_search.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with dask ml\n",
    "import joblib\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid_search.fit(X,Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motrainer-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
